# LLM Context Length Overflow Analysis

## Error Summary

```
Error: 400 This endpoint's maximum context length is 1048576 tokens.
However, you requested about 1293741 tokens
```

**è¶…å‡ºæƒ…å†µ**ï¼š
- ğŸš« æ¨¡å‹é™åˆ¶ï¼š1,048,576 tokens (~1M tokens)
- âš ï¸ å®é™…è¯·æ±‚ï¼š1,293,741 tokens (~1.29M tokens)
- ğŸ“Š è¶…å‡ºé‡ï¼š245,165 tokens (~23% è¶…å‡º)

**Token åˆ†å¸ƒ**ï¼š
- ğŸ“ æ–‡æœ¬è¾“å…¥ï¼š1,227,853 tokens (95%)
- ğŸ”§ å·¥å…·è¾“å…¥ï¼š353 tokens (<1%)
- ğŸ“¤ è¾“å‡ºé¢„ç•™ï¼š65,535 tokens (5%)

## é—®é¢˜æ ¹æº

ä»é”™è¯¯å †æ ˆå¯ä»¥çœ‹å‡ºï¼š
```
at SkillEngineService â†’ Agent skill execution
at OpenAI.makeRequest (openai/src/client.ts:713:24)
POST /v1/skill/streamInvoke
```

**æ ¸å¿ƒé—®é¢˜**ï¼šAgent skill åœ¨æ„å»º LLM è¯·æ±‚æ—¶ï¼Œå°†è¿‡å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼ é€’ç»™äº†æ¨¡å‹ã€‚

## ä»£ç åˆ†æ

### 1. æ¶ˆæ¯æ„å»ºæµç¨‹

#### æ–‡ä»¶ï¼š[packages/skill-template/src/scheduler/utils/message.ts](../../../../../../packages/skill-template/src/scheduler/utils/message.ts:52-128)

```typescript
export const buildFinalRequestMessages = ({
  module,
  locale,
  chatHistory,        // âš ï¸ å¯èƒ½å¾ˆé•¿
  messages,           // âš ï¸ é¢å¤–æ¶ˆæ¯
  context,            // âš ï¸ ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
  images,
  originalQuery,
  optimizedQuery,
  rewrittenQueries,
  modelInfo,
  customInstructions,
}) => {
  const systemPrompt = module.buildSystemPrompt(locale, !!context);
  const contextUserPrompt = module.buildContextUserPrompt?.(context, !!context);
  const userPrompt = module.buildUserPrompt({
    originalQuery,
    optimizedQuery,
    rewrittenQueries,
    locale,
    customInstructions,
  });

  // ç»„è£…æ‰€æœ‰æ¶ˆæ¯
  const requestMessages = [
    new SystemMessage(systemPrompt),     // ç³»ç»Ÿæç¤º
    ...chatHistory,                      // âš ï¸ å†å²å¯¹è¯ - å¯èƒ½éå¸¸é•¿
    ...messages,                         // âš ï¸ é¢å¤–æ¶ˆæ¯
    ...contextMessages,                  // âš ï¸ ä¸Šä¸‹æ–‡æ¶ˆæ¯ - å¯èƒ½éå¸¸é•¿
    finalUserMessage,                    // å½“å‰æŸ¥è¯¢
  ];

  return requestMessages;
};
```

**é—®é¢˜ç‚¹**ï¼š
1. âŒ `chatHistory` - æ²¡æœ‰é•¿åº¦é™åˆ¶ï¼Œå¯èƒ½åŒ…å«å‡ åç”šè‡³ä¸Šç™¾æ¡æ¶ˆæ¯
2. âŒ `context` - æ²¡æœ‰æœ‰æ•ˆå‹ç¼©ï¼Œå¯èƒ½åŒ…å«å¤§é‡æ–‡æ¡£å†…å®¹
3. âŒ `messages` - é¢å¤–æ¶ˆæ¯ç´¯ç§¯

### 2. ä¸Šä¸‹æ–‡å‡†å¤‡æµç¨‹

#### æ–‡ä»¶ï¼š[packages/skill-template/src/scheduler/utils/context.ts](../../../../../../packages/skill-template/src/scheduler/utils/context.ts:222-425)

```typescript
export async function prepareContext(
  query: string,
  context: SkillContext,
  options: {
    maxTokens: number;           // âš ï¸ å…³é”®å‚æ•°
    engine: SkillEngine;
    summarizerConcurrentLimit?: number;
  },
): Promise<{ contextStr: string }> {
  // ... æ„å»º blocks ...

  const contextStr = sections.length > 0
    ? `# Context\n\n${sections.join('\n\n')}`
    : '';

  if (maxTokens <= 0) {
    return { contextStr };        // âš ï¸ å¦‚æœ maxTokens = 0ï¼Œç›´æ¥è¿”å›æœªå‹ç¼©å†…å®¹
  }

  const totalTokens = encode(contextStr ?? '').length;
  if (totalTokens <= maxTokens) {
    return { contextStr };
  }

  // Middle-out compression
  return await compressContext(query, contextStr, blocks, options);
}
```

**å…³é”®å‘ç°**ï¼š
- âœ… ç³»ç»Ÿæœ‰ `compressContext` å‹ç¼©æœºåˆ¶
- âš ï¸ ä½†ä»…åœ¨ `maxTokens > 0` ä¸” `totalTokens > maxTokens` æ—¶æ‰å¯ç”¨
- âŒ å¦‚æœ `maxTokens` å‚æ•°è®¾ç½®ä¸å½“æˆ–ä¸º 0ï¼Œå‹ç¼©ä¸ä¼šç”Ÿæ•ˆ

### 3. ä¸Šä¸‹æ–‡å‹ç¼©ç®—æ³•

#### Middle-Out Compression

```typescript
const compressContext = async (
  query: string,
  contextStr: string,
  blocks: Block[],
  options: { maxTokens: number; engine: SkillEngine; },
) => {
  // 1. æ‰¾åˆ°å¯å‹ç¼©çš„ blocksï¼ˆbody éç©ºï¼‰
  const compressibleIndexes = blocks
    .map((b, i) => ({ i, tokens: encode(b.body ?? '').length }))
    .filter((x) => x.tokens > 0)
    .map((x) => x.i);

  // 2. ç”Ÿæˆ middle-out é¡ºåºï¼ˆä»ä¸­é—´å‘ä¸¤ç«¯ï¼‰
  const center = Math.floor((N - 1) / 2);
  // ... ç”Ÿæˆå‹ç¼©é¡ºåº ...

  // 3. è¿­ä»£å‹ç¼©ä¸­é—´çš„ blocksï¼Œç›´åˆ°ç¬¦åˆé¢„ç®—
  for (const idx of compressOrder) {
    if (currentTokens <= maxTokens) break;

    // ä½¿ç”¨ LLM å‹ç¼© body å†…å®¹åˆ° ~30% æˆ– 15% é¢„ç®—
    const targetBodyBudget = Math.max(
      64,
      Math.floor(Math.min(bodyTokens * 0.3, maxTokens * 0.15))
    );

    const summarized = await summarizer(
      summarizerModel,
      query,
      original?.body ?? '',
      targetBodyBudget,
    );
    currentBlocks[idx] = { ...original, body: summarized ?? '' };
  }

  // 4. å¦‚æœä»è¶…å‡ºé¢„ç®—ï¼Œå¼ºåˆ¶ fallback æˆªæ–­
  if (currentTokens > maxTokens) {
    const trimmed = await fallbackSummarize(query, currentStr, maxTokens);
    return { contextStr: trimmed };
  }

  return { contextStr: currentStr };
};
```

**ç®—æ³•ç‰¹ç‚¹**ï¼š
- âœ… æ™ºèƒ½ middle-out é¡ºåºï¼šä¼˜å…ˆä¿ç•™å¼€å¤´å’Œç»“å°¾çš„ä¸Šä¸‹æ–‡
- âœ… ä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰å‹ç¼©ï¼ˆä¿ç•™å…³é”®ä¿¡æ¯ï¼‰
- âœ… Fallback æœºåˆ¶ï¼šå¦‚æœå‹ç¼©åä»è¶…å‡ºï¼Œä½¿ç”¨ token-based æˆªæ–­

### 4. ä¸Šä¸‹æ–‡æ¥æºåˆ†æ

ä¸Šä¸‹æ–‡å¯èƒ½åŒ…å«ä»¥ä¸‹ç±»å‹ï¼ˆæŒ‰ token å ç”¨æ’åºï¼‰ï¼š

```typescript
// 1. Knowledge Base Documents - âš ï¸ é«˜é£é™©
if (context?.documents?.length > 0) {
  // æ¯ä¸ªæ–‡æ¡£å¯èƒ½åŒ…å«å‡ åƒåˆ°å‡ ä¸‡ tokens
  const items = context.documents.map(item => ({
    section: 'Knowledge Base Documents',
    body: doc?.content ?? '',  // âš ï¸ å®Œæ•´æ–‡æ¡£å†…å®¹
  }));
}

// 2. User Selected Content - âš ï¸ é«˜é£é™©
if (context?.contentList?.length > 0) {
  // ç”¨æˆ·é€‰æ‹©çš„å†…å®¹å¯èƒ½éå¸¸é•¿
  const items = context.contentList.map(item => ({
    section: 'User Selected Content',
    body: item?.content ?? '',  // âš ï¸ å®Œæ•´å†…å®¹
  }));
}

// 3. Previous Agent Results - âš ï¸ ä¸­ç­‰é£é™©
if (context?.results?.length > 0) {
  const items = context.results.map(item => ({
    section: 'Previous Agent Results',
    body: result?.steps?.map(step => step.content).join('\n\n'),
  }));
}

// 4. Code Artifacts - âš ï¸ ä¸­ç­‰é£é™©
if (context?.codeArtifacts?.length > 0) {
  const items = context.codeArtifacts.map(item => ({
    section: 'Code Artifacts',
    body: artifact?.content ?? '',  // ä»£ç å¯èƒ½å¾ˆé•¿
  }));
}

// 5. Files - âš ï¸ ä¸­ç­‰é£é™©
if (context?.files?.length > 0) {
  const items = context.files.map(item => ({
    section: 'Files',
    body: file?.content ?? '',
  }));
}
```

## é—®é¢˜å®šä½

### æœ€å¯èƒ½çš„åŸå› ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰

#### 1. **maxTokens å‚æ•°è®¾ç½®ä¸å½“** ğŸ”¥ (æœ€é«˜ä¼˜å…ˆçº§)

**ä½ç½®**ï¼šè°ƒç”¨ `prepareContext` æ—¶
```typescript
// âŒ é”™è¯¯ï¼šmaxTokens = 0 æˆ–æœªè®¾ç½®
const { contextStr } = await prepareContext(query, context, {
  maxTokens: 0,  // âš ï¸ æˆ–è€…æœªä¼ é€’
  engine,
});

// âœ… æ­£ç¡®ï¼šè®¾ç½®åˆç†çš„ maxTokens
const { contextStr } = await prepareContext(query, context, {
  maxTokens: 300000,  // ä¾‹å¦‚ï¼šä¸ºä¸Šä¸‹æ–‡é¢„ç•™ 300K tokens
  engine,
});
```

**æ£€æŸ¥æ–¹æ³•**ï¼šåœ¨ Agent skill ä»£ç ä¸­æŸ¥æ‰¾ `prepareContext` è°ƒç”¨

#### 2. **chatHistory æœªæˆªæ–­** ğŸ”¥ (é«˜ä¼˜å…ˆçº§)

**ä½ç½®**ï¼š`buildFinalRequestMessages` ä¸­
```typescript
const requestMessages = [
  new SystemMessage(systemPrompt),
  ...chatHistory,  // âš ï¸ å¯èƒ½åŒ…å«å‡ ç™¾æ¡æ¶ˆæ¯
  ...messages,
  ...contextMessages,
  finalUserMessage,
];
```

**è§£å†³æ–¹æ¡ˆ**ï¼šéœ€è¦é™åˆ¶ chatHistory çš„é•¿åº¦
```typescript
// âœ… åªä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯
const recentHistory = chatHistory.slice(-10);  // åªä¿ç•™æœ€è¿‘ 10 æ¡

const requestMessages = [
  new SystemMessage(systemPrompt),
  ...recentHistory,  // âœ… ä½¿ç”¨æˆªæ–­åçš„å†å²
  ...messages,
  ...contextMessages,
  finalUserMessage,
];
```

#### 3. **çŸ¥è¯†åº“æ£€ç´¢è¿”å›è¿‡å¤šæ–‡æ¡£** âš ï¸ (ä¸­ç­‰ä¼˜å…ˆçº§)

**ä½ç½®**ï¼šRAG æ£€ç´¢é€»è¾‘
```typescript
// âŒ è¿”å›å‡ åä¸ªæ–‡æ¡£
const documents = await retrieveDocuments(query, {
  topK: 50,  // âš ï¸ å¤ªå¤šäº†
});

// âœ… é™åˆ¶æ–‡æ¡£æ•°é‡
const documents = await retrieveDocuments(query, {
  topK: 5,   // âœ… æ›´åˆç†
});
```

#### 4. **Canvas ä¸Šä¸‹æ–‡è¿‡å¤§** âš ï¸ (ä¸­ç­‰ä¼˜å…ˆçº§)

**ä½ç½®**ï¼šCanvas èŠ‚ç‚¹å’Œèµ„æºæ”¶é›†
```typescript
// å¯èƒ½æ”¶é›†äº†å¤§é‡èŠ‚ç‚¹çš„è¾“å‡ºç»“æœ
const canvasContext = {
  nodes: [...],      // å‡ åä¸ªèŠ‚ç‚¹
  resources: [...],  // å¤§é‡èµ„æº
};
```

## è¯Šæ–­æ­¥éª¤

### æ­¥éª¤ 1ï¼šæ·»åŠ æ—¥å¿—ç›‘æ§

åœ¨å…³é”®ä½ç½®æ·»åŠ  token è®¡æ•°æ—¥å¿—ï¼š

```typescript
// åœ¨ prepareContext ä¸­
export async function prepareContext(
  query: string,
  context: SkillContext,
  options: { maxTokens: number; engine: SkillEngine },
) {
  // ... æ„å»º contextStr ...

  const totalTokens = encode(contextStr ?? '').length;

  // âœ… æ·»åŠ æ—¥å¿—
  options.engine.logger.log(
    `[Context Debug] Total context tokens: ${totalTokens}, ` +
    `maxTokens: ${options.maxTokens}, ` +
    `will compress: ${totalTokens > options.maxTokens && options.maxTokens > 0}`
  );

  // ... å‹ç¼©é€»è¾‘ ...
}

// åœ¨ buildFinalRequestMessages ä¸­
export const buildFinalRequestMessages = ({
  chatHistory,
  messages,
  context,
  // ...
}) => {
  const requestMessages = [/* ... */];

  // âœ… æ·»åŠ æ—¥å¿—
  const totalTokens = requestMessages.reduce((sum, msg) => {
    const content = typeof msg.content === 'string'
      ? msg.content
      : JSON.stringify(msg.content);
    return sum + encode(content).length;
  }, 0);

  console.log(
    `[Message Debug] Total message tokens: ${totalTokens}, ` +
    `chatHistory: ${chatHistory.length} msgs, ` +
    `context length: ${encode(context).length} tokens`
  );

  return requestMessages;
};
```

### æ­¥éª¤ 2ï¼šæ£€æŸ¥é…ç½®

æŸ¥æ‰¾ä»¥ä¸‹æ–‡ä»¶ä¸­çš„é…ç½®ï¼š

1. **Agent skill å®ç°**
   ```bash
   # æ£€æŸ¥ maxTokens å‚æ•°
   grep -n "prepareContext" packages/skill-template/src/skills/agent.ts
   grep -n "maxTokens" packages/skill-template/src/skills/agent.ts
   ```

2. **Skill engine é…ç½®**
   ```bash
   # æ£€æŸ¥æ¨¡å‹é…ç½®
   grep -n "contextLength\|maxTokens" apps/api/src/modules/skill/
   ```

### æ­¥éª¤ 3ï¼šéªŒè¯å‹ç¼©æ˜¯å¦ç”Ÿæ•ˆ

ä¸´æ—¶ä¿®æ”¹ä»£ç ï¼Œå¼ºåˆ¶å‹ç¼©ï¼š

```typescript
// åœ¨ prepareContext ä¸­
export async function prepareContext(
  query: string,
  context: SkillContext,
  options: { maxTokens: number; engine: SkillEngine },
) {
  // ... æ„å»º contextStr ...

  const totalTokens = encode(contextStr ?? '').length;

  // âœ… å¼ºåˆ¶å‹ç¼©ï¼ˆç”¨äºæµ‹è¯•ï¼‰
  const forceMaxTokens = Math.min(
    options.maxTokens || 300000,
    300000  // å¼ºåˆ¶ä¸Šé™ 300K
  );

  if (totalTokens > forceMaxTokens) {
    options.engine.logger.warn(
      `[Context Compression] Forcing compression from ${totalTokens} to ${forceMaxTokens} tokens`
    );
    return await compressContext(query, contextStr, blocks, {
      ...options,
      maxTokens: forceMaxTokens,
    });
  }

  return { contextStr };
}
```

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šè®¾ç½®åˆç†çš„ maxTokensï¼ˆæ¨èï¼‰

æ‰¾åˆ°è°ƒç”¨ `prepareContext` çš„åœ°æ–¹ï¼Œç¡®ä¿è®¾ç½®äº†åˆç†çš„ `maxTokens`ï¼š

```typescript
// æ–‡ä»¶ï¼špackages/skill-template/src/skills/agent.ts

const { contextStr } = await prepareContext(query, context, {
  // âœ… ä¸ºä¸Šä¸‹æ–‡é¢„ç•™åˆç†çš„ token é¢„ç®—
  // æ¨¡å‹æ€»é™åˆ¶ï¼š1,048,576 tokens
  // - ç³»ç»Ÿæç¤ºï¼š~5,000 tokens
  // - å¯¹è¯å†å²ï¼š~50,000 tokens (ä¿ç•™æœ€è¿‘ 10-20 æ¡)
  // - ç”¨æˆ·æŸ¥è¯¢ï¼š~1,000 tokens
  // - è¾“å‡ºé¢„ç•™ï¼š65,535 tokens
  // = å‰©ä½™å¯ç”¨ï¼š~926,000 tokens
  // ä¿å®ˆä¼°è®¡ï¼Œä¸ºä¸Šä¸‹æ–‡åˆ†é… 300K-500K tokens
  maxTokens: 300000,  // 300K tokens for context
  engine,
});
```

### æ–¹æ¡ˆ 2ï¼šæˆªæ–­ chatHistory

åœ¨æ„å»ºæ¶ˆæ¯æ—¶é™åˆ¶å†å²é•¿åº¦ï¼š

```typescript
// æ–‡ä»¶ï¼špackages/skill-template/src/scheduler/utils/message.ts

export const buildFinalRequestMessages = ({
  module,
  locale,
  chatHistory,
  messages,
  context,
  // ...
}) => {
  // âœ… é™åˆ¶ chatHistory é•¿åº¦
  const MAX_HISTORY_MESSAGES = 20;
  const recentHistory = chatHistory?.slice(-MAX_HISTORY_MESSAGES) ?? [];

  // âœ… æˆ–è€…åŸºäº token é¢„ç®—æˆªæ–­
  const truncatedHistory = truncateHistoryByTokens(chatHistory, 50000);

  const requestMessages = [
    new SystemMessage(systemPrompt),
    ...truncatedHistory,  // âœ… ä½¿ç”¨æˆªæ–­åçš„å†å²
    ...messages,
    ...contextMessages,
    finalUserMessage,
  ];

  return requestMessages;
};

// è¾…åŠ©å‡½æ•°ï¼šæŒ‰ token é¢„ç®—æˆªæ–­å†å²
function truncateHistoryByTokens(
  history: BaseMessage[],
  maxTokens: number
): BaseMessage[] {
  let totalTokens = 0;
  const result: BaseMessage[] = [];

  // ä»æœ€æ–°çš„æ¶ˆæ¯å¼€å§‹å‘å‰ç´¯ç§¯
  for (let i = history.length - 1; i >= 0; i--) {
    const msg = history[i];
    const content = typeof msg.content === 'string'
      ? msg.content
      : JSON.stringify(msg.content);
    const tokens = encode(content).length;

    if (totalTokens + tokens > maxTokens) {
      break;
    }

    totalTokens += tokens;
    result.unshift(msg);
  }

  return result;
}
```

### æ–¹æ¡ˆ 3ï¼šæ™ºèƒ½ä¸Šä¸‹æ–‡é€‰æ‹©

ä¼˜å…ˆé€‰æ‹©æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼š

```typescript
// æ–‡ä»¶ï¼špackages/skill-template/src/scheduler/utils/context.ts

export async function prepareContext(
  query: string,
  context: SkillContext,
  options: { maxTokens: number; engine: SkillEngine },
) {
  // âœ… å¯¹å„ç±»ä¸Šä¸‹æ–‡è¿›è¡Œä¼˜å…ˆçº§æ’åº
  const allBlocks: Array<Block & { priority: number }> = [];

  // é«˜ä¼˜å…ˆçº§ï¼šç”¨æˆ·é€‰æ‹©çš„å†…å®¹
  if (context?.contentList?.length > 0) {
    const items = context.contentList.map((item, index) => ({
      section: 'User Selected Content',
      prefix: `### ${item.metadata?.title || 'Content'}\n\n`,
      body: item?.content ?? '',
      suffix: '',
      priority: 100 - index,  // âœ… é«˜ä¼˜å…ˆçº§
    }));
    allBlocks.push(...items);
  }

  // ä¸­ä¼˜å…ˆçº§ï¼šçŸ¥è¯†åº“æ–‡æ¡£ï¼ˆæŒ‰ç›¸å…³åº¦æ’åºï¼‰
  if (context?.documents?.length > 0) {
    const items = context.documents
      .sort((a, b) => (b.score || 0) - (a.score || 0))  // âœ… æŒ‰ç›¸å…³åº¦æ’åº
      .slice(0, 5)  // âœ… åªå–å‰ 5 ä¸ªæœ€ç›¸å…³çš„
      .map((item, index) => ({
        section: 'Knowledge Base Documents',
        prefix: `### ${item.document?.title}\n\n`,
        body: item.document?.content ?? '',
        suffix: '',
        priority: 80 - index,  // âœ… ä¸­ä¼˜å…ˆçº§
      }));
    allBlocks.push(...items);
  }

  // ä½ä¼˜å…ˆçº§ï¼šå…¶ä»–èµ„æº
  // ...

  // âœ… æŒ‰ä¼˜å…ˆçº§æ’åº
  allBlocks.sort((a, b) => b.priority - a.priority);

  // âœ… é€ä¸ªæ·»åŠ  blocksï¼Œç›´åˆ°è¾¾åˆ° token é¢„ç®—
  const selectedBlocks: Block[] = [];
  let currentTokens = 0;

  for (const block of allBlocks) {
    const blockTokens = encode(
      `${block.prefix}${block.body}${block.suffix}`
    ).length;

    if (currentTokens + blockTokens > options.maxTokens) {
      // å¦‚æœæ·»åŠ è¿™ä¸ª block ä¼šè¶…å‡ºé¢„ç®—ï¼Œå°è¯•å‹ç¼©å®ƒ
      const remainingBudget = options.maxTokens - currentTokens;
      if (remainingBudget > 1000) {  // è‡³å°‘ 1K tokens æ‰å€¼å¾—å‹ç¼©
        const compressed = await summarizer(
          engine.chatModel({ temperature: 0 }, 'queryAnalysis'),
          query,
          block.body,
          remainingBudget * 0.8,  // ä½¿ç”¨ 80% çš„å‰©ä½™é¢„ç®—
        );
        selectedBlocks.push({
          ...block,
          body: compressed,
        });
        currentTokens += encode(compressed).length;
      }
      break;
    }

    selectedBlocks.push(block);
    currentTokens += blockTokens;
  }

  // æ¸²æŸ“é€‰ä¸­çš„ blocks
  const contextStr = renderAll(selectedBlocks);
  return { contextStr };
}
```

### æ–¹æ¡ˆ 4ï¼šåŠ¨æ€é¢„ç®—åˆ†é…

æ ¹æ®æ¨¡å‹é™åˆ¶åŠ¨æ€è®¡ç®—é¢„ç®—ï¼š

```typescript
// æ–‡ä»¶ï¼špackages/skill-template/src/skills/agent.ts

const calculateContextBudget = (
  modelConfig: LLMModelConfig,
  chatHistory: BaseMessage[],
  systemPromptLength: number,
) => {
  // æ¨¡å‹çš„æ€» token é™åˆ¶
  const modelMaxTokens = modelConfig.contextLength || 1048576;

  // é¢„ç•™ç»™å„éƒ¨åˆ†çš„ tokens
  const reservedForOutput = 65535;  // è¾“å‡ºé¢„ç•™
  const systemPromptTokens = encode(systemPromptLength).length;

  // ä¼°ç®— chatHistory tokens
  const historyTokens = chatHistory.reduce((sum, msg) => {
    const content = typeof msg.content === 'string'
      ? msg.content
      : JSON.stringify(msg.content);
    return sum + encode(content).length;
  }, 0);

  // é¢„ç•™ç»™å…¶ä»–æ¶ˆæ¯
  const reservedForOther = 10000;

  // è®¡ç®—å¯ç”¨äºä¸Šä¸‹æ–‡çš„ tokens
  const availableForContext = Math.max(
    50000,  // è‡³å°‘ 50K
    modelMaxTokens - reservedForOutput - systemPromptTokens - historyTokens - reservedForOther
  );

  return Math.min(availableForContext, 500000);  // æœ€å¤š 500K
};

// ä½¿ç”¨åŠ¨æ€é¢„ç®—
const contextBudget = calculateContextBudget(
  modelConfig,
  chatHistory,
  systemPrompt.length,
);

const { contextStr } = await prepareContext(query, context, {
  maxTokens: contextBudget,
  engine,
});
```

## ç«‹å³è¡ŒåŠ¨å»ºè®®

### ğŸš¨ ç´§æ€¥ä¿®å¤ï¼ˆä¸´æ—¶ï¼‰

1. **æ‰¾åˆ°å¹¶ä¿®æ”¹ Agent skill ä¸­çš„ `prepareContext` è°ƒç”¨**
   ```typescript
   // ä¸´æ—¶ç¡¬ç¼–ç ä¸€ä¸ªå®‰å…¨çš„ maxTokens
   const { contextStr } = await prepareContext(query, context, {
     maxTokens: 200000,  // âœ… ä¸´æ—¶å›ºå®šä¸º 200K
     engine,
   });
   ```

2. **æˆªæ–­ chatHistory**
   ```typescript
   // ä¸´æ—¶é™åˆ¶å†å²æ¶ˆæ¯æ•°é‡
   const recentHistory = chatHistory.slice(-15);  // åªä¿ç•™æœ€è¿‘ 15 æ¡
   ```

### ğŸ”§ é•¿æœŸä¼˜åŒ–

1. **å®ç°æ™ºèƒ½é¢„ç®—åˆ†é…ç³»ç»Ÿ**
   - æ ¹æ®æ¨¡å‹é™åˆ¶åŠ¨æ€è®¡ç®—
   - ç›‘æ§å®é™… token ä½¿ç”¨æƒ…å†µ
   - è®°å½•æ—¥å¿—ç”¨äºè°ƒä¼˜

2. **ä¼˜åŒ–ä¸Šä¸‹æ–‡é€‰æ‹©ç­–ç•¥**
   - æŒ‰ç›¸å…³åº¦æ’åº
   - ä¼˜å…ˆçº§æœºåˆ¶
   - æ™ºèƒ½å‹ç¼©

3. **æ·»åŠ ç›‘æ§å’Œå‘Šè­¦**
   - Token ä½¿ç”¨ç‡ç›‘æ§
   - è¶…å‡ºè­¦å‘Šæ—¥å¿—
   - æ€§èƒ½æŒ‡æ ‡æ”¶é›†

## éªŒè¯ä¿®å¤

ä¿®å¤åï¼Œåº”è¯¥èƒ½çœ‹åˆ°ï¼š

```
âœ… Total context tokens: 250000, maxTokens: 300000, will compress: false
âœ… Total message tokens: 850000 < 1048576 (model limit)
âœ… Request successful without overflow error
```

## ç›¸å…³æ–‡ä»¶

- [message.ts](../../../../../../packages/skill-template/src/scheduler/utils/message.ts) - æ¶ˆæ¯æ„å»º
- [context.ts](../../../../../../packages/skill-template/src/scheduler/utils/context.ts) - ä¸Šä¸‹æ–‡å‡†å¤‡å’Œå‹ç¼©
- [agent.ts](../../../../../../packages/skill-template/src/skills/agent.ts) - Agent skill å®ç°

## æ€»ç»“

**æ ¹æœ¬åŸå› **ï¼šä¸Šä¸‹æ–‡ token é¢„ç®—ç®¡ç†ä¸å½“ï¼Œå¯¼è‡´ä¼ é€’ç»™ LLM çš„å†…å®¹è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚

**æ ¸å¿ƒä¿®å¤**ï¼š
1. âœ… ä¸º `prepareContext` è®¾ç½®åˆç†çš„ `maxTokens` å‚æ•°
2. âœ… æˆªæ–­æˆ–å‹ç¼© `chatHistory`
3. âœ… ä¼˜åŒ–ä¸Šä¸‹æ–‡é€‰æ‹©ç­–ç•¥

**éªŒè¯æ–¹æ³•**ï¼š
1. æ·»åŠ  token è®¡æ•°æ—¥å¿—
2. ç›‘æ§å®é™…ä½¿ç”¨æƒ…å†µ
3. æµ‹è¯•è¾¹ç•Œåœºæ™¯
