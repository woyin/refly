# Debug mode
DEBUG=false

# LiteLLM API Configuration (Recommended - supports multiple models via OpenAI-compatible API)
# LiteLLM provides a unified interface for multiple LLM providers
OPENAI_API_KEY=your_litellm_api_key_here
OPENAI_BASE_URL=https://litellm.powerformer.net/v1

# Azure OpenAI Configuration (optional)
# AZURE_OPENAI_API_KEY=your_azure_key
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2023-05-15
# AZURE_DEPLOYMENT_NAME=your_deployment_name

# Anthropic API Configuration (optional)
# ANTHROPIC_API_KEY=your_anthropic_key

# LLM Settings
# For LiteLLM, use the model name directly (e.g., gpt-4-turbo, claude-3-opus, gemini-pro)
# LiteLLM handles the provider routing automatically
MODEL=gpt-3.5-turbo
TEMPERATURE=0.03
DETAILED_ERROR=true
REQUEST_TIMEOUT=300  # Timeout in seconds (5 minutes recommended)
MAX_ITERATIONS=12
MAX_RETRY=3

# Production Settings (optional)
# HISTORY_BACKEND=redis
# REDIS_URL=redis://localhost:6379
# POSTGRES_URL=postgresql://postgres:postgres@localhost:5432/postgres

# CodeBox Settings
# CODEBOX_API_KEY=your_codebox_api_key
# CUSTOM_PACKAGES=pandas,numpy,matplotlib

# Custom System Message (optional)
# SYSTEM_MESSAGE=Your custom system message here

SCALEBOX_API_KEY=